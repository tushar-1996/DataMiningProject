{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "MasterEnsemble.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxSQ0GBTOx8i"
      },
      "source": [
        "import os\n",
        "import tweepy as tw\n",
        "import pandas as pd\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from nltk.corpus import stopwords\n",
        "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import numpy as np\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras.models\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFGsFBF0PIN3",
        "outputId": "1a1d4392-a31a-483b-c7b3-102ad9b9d02f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1GQXlPMOx8k"
      },
      "source": [
        "extension = 'csv'\n",
        "all_filenames = [i for i in glob.glob('/content/drive/MyDrive/twit/train/*.{}'.format(extension))]\n",
        "\n",
        "#combine all files in the list\n",
        "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
        "#export to csv\n",
        "combined_csv.to_csv( \"aggregate.csv\", index=False, encoding='utf-8-sig')"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Zl2_zX5UOx8n",
        "outputId": "a6a222d0-363d-4b14-f5ab-b1cbadd43b4a"
      },
      "source": [
        "\n",
        "names = ['TweetID', 'Sentiment', 'Tweet']\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/twit/train/aggregate.csv')\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>Column2</th>\n",
              "      <th>Column3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.380610e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>05 Beat it - Michael Jackson - Thriller (25th ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.380610e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>Jay Z joins Instagram with nostalgic tribute t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.380840e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Michael Jackson: Bad 25th Anniversary Edition ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.380910e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>I liked a @YouTube video http://t.co/AaR3pjp2P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.381260e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>18th anniv of Princess Diana's death. I still ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Column1   Column2                                            Column3\n",
              "0  6.380610e+17   neutral  05 Beat it - Michael Jackson - Thriller (25th ...\n",
              "1  6.380610e+17  positive  Jay Z joins Instagram with nostalgic tribute t...\n",
              "2  6.380840e+17   neutral  Michael Jackson: Bad 25th Anniversary Edition ...\n",
              "3  6.380910e+17  positive  I liked a @YouTube video http://t.co/AaR3pjp2P...\n",
              "4  6.381260e+17  positive  18th anniv of Princess Diana's death. I still ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHMAxp3_Gjea"
      },
      "source": [
        "def remove_pattern(input_txt, pattern):\r\n",
        "  r = re.findall(pattern, input_txt)\r\n",
        "  for i in r:\r\n",
        "    input_txt = re.sub(i, '', input_txt)        \r\n",
        "  return input_txt\r\n",
        "\r\n",
        "def clean_tweets(frame, column_name):\r\n",
        "  frame = frame.drop_duplicates().reset_index(drop=True) #remove duplicate rows\r\n",
        "  frame['Tweet_Clean_Text'] = np.vectorize(remove_pattern)(frame[column_name], \"RT @[\\w]*:\") #remove twitter return handle\r\n",
        "  frame.Tweet_Clean_Text = np.vectorize(remove_pattern)(frame['Tweet_Clean_Text'], \"@[\\w]*\") #remove twitter handle\r\n",
        "  frame.Tweet_Clean_Text = np.vectorize(remove_pattern)(frame['Tweet_Clean_Text'], \"https?://[A-Za-z0-9./]*\") #remove URLs\r\n",
        "  frame.Tweet_Clean_Text = frame.Tweet_Clean_Text.str.replace(\"[^a-zA-Z#]\", \" \") #remove special characters except for #\r\n",
        "  frame.Tweet_Clean_Text = frame.Tweet_Clean_Text.replace('\\s+', ' ', regex=True) #remove extra spaces in between words\r\n",
        "\r\n",
        "  return frame"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XHk6IGNMOx8p",
        "outputId": "3e4205a1-25c3-42f2-9fde-92e62d0585e3"
      },
      "source": [
        "train_set = clean_tweets(train, 'Column3')\r\n",
        "train_set.head()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>Column2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Tweet_Clean_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.380610e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>05 Beat it - Michael Jackson - Thriller (25th ...</td>\n",
              "      <td>Beat it Michael Jackson Thriller th Anniversa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.380610e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>Jay Z joins Instagram with nostalgic tribute t...</td>\n",
              "      <td>Jay Z joins Instagram with nostalgic tribute t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.380840e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Michael Jackson: Bad 25th Anniversary Edition ...</td>\n",
              "      <td>Michael Jackson Bad th Anniversary Edition Pic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.380910e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>I liked a @YouTube video http://t.co/AaR3pjp2P...</td>\n",
              "      <td>I liked a video One Direction singing Man in t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.381260e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>18th anniv of Princess Diana's death. I still ...</td>\n",
              "      <td>th anniv of Princess Diana s death I still wa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Column1  ...                                   Tweet_Clean_Text\n",
              "0  6.380610e+17  ...   Beat it Michael Jackson Thriller th Anniversa...\n",
              "1  6.380610e+17  ...  Jay Z joins Instagram with nostalgic tribute t...\n",
              "2  6.380840e+17  ...  Michael Jackson Bad th Anniversary Edition Pic...\n",
              "3  6.380910e+17  ...  I liked a video One Direction singing Man in t...\n",
              "4  6.381260e+17  ...   th anniv of Princess Diana s death I still wa...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ueTzZRHxOx8t",
        "outputId": "5be1658d-3f7b-48ad-cc69-cf17883a47c5"
      },
      "source": [
        "train_set[\"Sentiment_Value\"] = train_set[\"Column2\"].map({\"neutral\": 0, \"positive\": 1, \"negative\": 2})\n",
        "label = to_categorical(train_set[\"Sentiment_Value\"], 3)\n",
        "train_set"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>Column2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Tweet_Clean_Text</th>\n",
              "      <th>Sentiment_Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.380610e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>05 Beat it - Michael Jackson - Thriller (25th ...</td>\n",
              "      <td>Beat it Michael Jackson Thriller th Anniversa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.380610e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>Jay Z joins Instagram with nostalgic tribute t...</td>\n",
              "      <td>Jay Z joins Instagram with nostalgic tribute t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.380840e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Michael Jackson: Bad 25th Anniversary Edition ...</td>\n",
              "      <td>Michael Jackson Bad th Anniversary Edition Pic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.380910e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>I liked a @YouTube video http://t.co/AaR3pjp2P...</td>\n",
              "      <td>I liked a video One Direction singing Man in t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.381260e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>18th anniv of Princess Diana's death. I still ...</td>\n",
              "      <td>th anniv of Princess Diana s death I still wa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114213</th>\n",
              "      <td>6.390170e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@YouAreMyArsenal Wouldn't surprise me if we en...</td>\n",
              "      <td>Wouldn t surprise me if we enquired He can t ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114214</th>\n",
              "      <td>6.402770e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Rib injury for Zlatan against Russia is a big ...</td>\n",
              "      <td>Rib injury for Zlatan against Russia is a big ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114215</th>\n",
              "      <td>6.402970e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Noooooo! I was hoping to see Zlatan being Zlat...</td>\n",
              "      <td>Noooooo I was hoping to see Zlatan being Zlata...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114216</th>\n",
              "      <td>6.410170e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@Fronsoir Zlatan has never done it on a wet Tu...</td>\n",
              "      <td>Zlatan has never done it on a wet Tuesday nig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114217</th>\n",
              "      <td>6.413960e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@ZIatanVines  how many goals Zlatan intends to...</td>\n",
              "      <td>how many goals Zlatan intends to serve into t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114218 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Column1  ... Sentiment_Value\n",
              "0       6.380610e+17  ...               0\n",
              "1       6.380610e+17  ...               1\n",
              "2       6.380840e+17  ...               0\n",
              "3       6.380910e+17  ...               1\n",
              "4       6.381260e+17  ...               1\n",
              "...              ...  ...             ...\n",
              "114213  6.390170e+17  ...               0\n",
              "114214  6.402770e+17  ...               0\n",
              "114215  6.402970e+17  ...               0\n",
              "114216  6.410170e+17  ...               0\n",
              "114217  6.413960e+17  ...               0\n",
              "\n",
              "[114218 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSXqcziYOx8u",
        "outputId": "23cfbfd4-6cea-4564-9250-01348b706fca"
      },
      "source": [
        "y_labels = train_set['Sentiment_Value']\n",
        "y_labels.shape"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114218,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRyal2-9GvfW"
      },
      "source": [
        "sequence_length = 47 #using the maximum length "
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BrfvQmpOx8v",
        "outputId": "5671562b-7c72-4057-e586-01dae12dc0cb"
      },
      "source": [
        "max_features = 2500\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ', oov_token='<unw>')\n",
        "tokenizer.fit_on_texts(train_set['Tweet_Clean_Text'].values)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(train_set['Tweet_Clean_Text'].values)\n",
        "X = pad_sequences(X, sequence_length)\n",
        "x_train = X\n",
        "\n",
        "print(\"training size \" + str(len(x_train)))\n",
        "\n",
        "voc_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocab size: \", voc_size)\n",
        "print(\"Input shape: \", x_train.shape)\n",
        "print(\"Y_shape: \" , y_labels.shape)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training size 114218\n",
            "Vocab size:  63987\n",
            "Input shape:  (114218, 47)\n",
            "Y_shape:  (114218,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Cb6FfSOx8w"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_labels, test_size=0.10, shuffle=False, random_state=10)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsnkTWO-Ox8w"
      },
      "source": [
        "def recall_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    recall_score.__name__ = 'recall'\n",
        "    return recall\n",
        "\n",
        "def precision_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    precision_score.__name__ = 'precision'\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1_metrics.__name__ = 'f1'\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "metrics = [\n",
        "           keras.metrics.CategoricalAccuracy(),\n",
        "           keras.metrics.Precision(name='precision'),\n",
        "           keras.metrics.Recall(name='recall'),\n",
        "           f1_metrics,\n",
        "           #keras.metrics.TruePositives(name='tp'),\n",
        "           #keras.metrics.FalsePositives(name='fp'),\n",
        "           #keras.metrics.TrueNegatives(name='tn'),\n",
        "           #keras.metrics.FalseNegatives(name='fn'),\n",
        "]\n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btoXteOMOx8y",
        "outputId": "6782526d-7522-46e8-cda0-f0a68859546c"
      },
      "source": [
        "# stacked generalization with neural net meta model on blobs dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import concatenate\n",
        "from numpy import argmax\n",
        "\n",
        "# load models from file\n",
        "def load_all_models(model_names):\n",
        "\tall_models = list()\n",
        "\tfor model_name in model_names:\n",
        "\t\t# define filename for this ensemble\n",
        "\t\tfilename = '/content/drive/MyDrive/Models/' + model_name\n",
        "\t\t# load model from file\n",
        "\t\tmodel = load_model(filename,custom_objects={'f1':f1_metrics,'precision':precision_score,'recall':recall_score})\n",
        "\t\t# add to list of members\n",
        "\t\tall_models.append(model)\n",
        "\t\tprint('>loaded %s' % filename)\n",
        "\treturn all_models\n",
        "\n",
        "# load all models\n",
        "members = ['LSTM532.h5', 'LSTM456.h5', 'LSTM352.h5', 'LSTM256.h5', 'LSTM200.h5']\n",
        "members = load_all_models(members)\n",
        "print('Loaded %d models' % len(members))\n",
        "\n",
        "train_predictions = []\n",
        "test_predictions = []\n",
        "\n",
        "for model in members:\n",
        "  train_predictions.append(model.predict([x_train], batch_size=1024))\n",
        "  test_predictions.append(model.predict([x_test], batch_size=1024))\n",
        "  print('Predicted one thing')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            ">loaded /content/drive/MyDrive/Models/LSTM532.h5\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            ">loaded /content/drive/MyDrive/Models/LSTM456.h5\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            ">loaded /content/drive/MyDrive/Models/LSTM352.h5\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            ">loaded /content/drive/MyDrive/Models/LSTM256.h5\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            ">loaded /content/drive/MyDrive/Models/LSTM200.h5\n",
            "Loaded 5 models\n",
            "Predicted one thing\n",
            "Predicted one thing\n",
            "Predicted one thing\n",
            "Predicted one thing\n",
            "Predicted one thing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPWOodkLl7hj"
      },
      "source": [
        "from keras.layers import BatchNormalization\r\n",
        "def ensemble(predictions, targets):\r\n",
        "    layer_size = len(predictions)\r\n",
        "    inp = Input(shape=(layer_size,3))\r\n",
        "    f0 = Flatten()(inp)\r\n",
        "    d0 = Dropout(0.2)(f0)\r\n",
        "    d0 = Dense(pow(layer_size, 4))(d0)\r\n",
        "    d1 = Dropout(0.2)(d0)\r\n",
        "    d1 = Dense(20 * layer_size)(d1)\r\n",
        "    b = BatchNormalization()(d1)\r\n",
        "    out = Dropout(0.2)(b)\r\n",
        "    out = Dense(3, activation='sigmoid')(out)\r\n",
        "\r\n",
        "    model = Model(inputs=inp, outputs=out)\r\n",
        "    metrics = [\r\n",
        "           keras.metrics.CategoricalAccuracy(),\r\n",
        "           keras.metrics.Precision(name='precision'),\r\n",
        "           keras.metrics.Recall(name='recall'),\r\n",
        "           f1_metrics,\r\n",
        "           #keras.metrics.TruePositives(name='tp'),\r\n",
        "           #keras.metrics.FalsePositives(name='fp'),\r\n",
        "           #keras.metrics.TrueNegatives(name='tn'),\r\n",
        "           #keras.metrics.FalseNegatives(name='fn'),\r\n",
        "  ]\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)\r\n",
        "    model.summary()\r\n",
        "\r\n",
        "    x = np.array(list(zip(*np.squeeze(predictions))))\r\n",
        "    y = targets\r\n",
        "    print(np.shape(x))\r\n",
        "    print(np.shape(y))\r\n",
        "    \r\n",
        "    history_flat_CNN = model.fit(x=x, y=y, epochs=20, validation_split=0.05, verbose=2)\r\n",
        "    #display_model_history(history_flat_CNN) \r\n",
        "    #plot_metrics(history_flat_CNN)\r\n",
        "    return model, history_flat_CNN"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Torxmyr7Ox8z",
        "outputId": "ad7ef813-8900-4b15-fa5d-531a7dac9367"
      },
      "source": [
        "y_train_cat = to_categorical(y_train,3)\r\n",
        "y_dev_cat = to_categorical(y_test,3)    \r\n",
        "stack_model, history = ensemble(train_predictions, y_train_cat)\r\n",
        "\r\n",
        "stacked_test_predictions = np.array(list(zip(*np.squeeze(test_predictions))))\r\n",
        "stacked_test_predictions = stack_model.predict(stacked_test_predictions, batch_size=1024)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 5, 3)]            0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 625)               10000     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 625)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 100)               62600     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 73,303\n",
            "Trainable params: 73,103\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "(102796, 5, 3)\n",
            "(102796, 3)\n",
            "Epoch 1/20\n",
            "3052/3052 - 13s - loss: 0.6404 - categorical_accuracy: 0.7460 - precision: 0.5012 - recall: 0.7899 - f1_metrics: 0.6133 - val_loss: 0.6897 - val_categorical_accuracy: 0.7130 - val_precision: 0.6187 - val_recall: 0.6414 - val_f1_metrics: 0.6298\n",
            "Epoch 2/20\n",
            "3052/3052 - 11s - loss: 0.6235 - categorical_accuracy: 0.7494 - precision: 0.5182 - recall: 0.8521 - f1_metrics: 0.6448 - val_loss: 0.6988 - val_categorical_accuracy: 0.7103 - val_precision: 0.5807 - val_recall: 0.7899 - val_f1_metrics: 0.6711\n",
            "Epoch 3/20\n",
            "3052/3052 - 11s - loss: 0.6201 - categorical_accuracy: 0.7498 - precision: 0.5407 - recall: 0.8704 - f1_metrics: 0.6675 - val_loss: 0.7010 - val_categorical_accuracy: 0.7113 - val_precision: 0.6315 - val_recall: 0.7481 - val_f1_metrics: 0.6859\n",
            "Epoch 4/20\n",
            "3052/3052 - 11s - loss: 0.6226 - categorical_accuracy: 0.7485 - precision: 0.5495 - recall: 0.8662 - f1_metrics: 0.6728 - val_loss: 0.7037 - val_categorical_accuracy: 0.7074 - val_precision: 0.6002 - val_recall: 0.7936 - val_f1_metrics: 0.6845\n",
            "Epoch 5/20\n",
            "3052/3052 - 11s - loss: 0.6209 - categorical_accuracy: 0.7496 - precision: 0.5587 - recall: 0.8752 - f1_metrics: 0.6824 - val_loss: 0.6994 - val_categorical_accuracy: 0.7117 - val_precision: 0.6201 - val_recall: 0.7817 - val_f1_metrics: 0.6926\n",
            "Epoch 6/20\n",
            "3052/3052 - 11s - loss: 0.6200 - categorical_accuracy: 0.7497 - precision: 0.5683 - recall: 0.8683 - f1_metrics: 0.6873 - val_loss: 0.7016 - val_categorical_accuracy: 0.7088 - val_precision: 0.6349 - val_recall: 0.7749 - val_f1_metrics: 0.6988\n",
            "Epoch 7/20\n",
            "3052/3052 - 11s - loss: 0.6209 - categorical_accuracy: 0.7488 - precision: 0.5740 - recall: 0.8682 - f1_metrics: 0.6915 - val_loss: 0.6953 - val_categorical_accuracy: 0.7134 - val_precision: 0.6374 - val_recall: 0.7947 - val_f1_metrics: 0.7080\n",
            "Epoch 8/20\n",
            "3052/3052 - 11s - loss: 0.6199 - categorical_accuracy: 0.7502 - precision: 0.5797 - recall: 0.8703 - f1_metrics: 0.6963 - val_loss: 0.6976 - val_categorical_accuracy: 0.7068 - val_precision: 0.6479 - val_recall: 0.7909 - val_f1_metrics: 0.7129\n",
            "Epoch 9/20\n",
            "3052/3052 - 11s - loss: 0.6189 - categorical_accuracy: 0.7501 - precision: 0.5912 - recall: 0.8662 - f1_metrics: 0.7033 - val_loss: 0.6947 - val_categorical_accuracy: 0.7119 - val_precision: 0.6448 - val_recall: 0.7891 - val_f1_metrics: 0.7104\n",
            "Epoch 10/20\n",
            "3052/3052 - 11s - loss: 0.6195 - categorical_accuracy: 0.7502 - precision: 0.6027 - recall: 0.8668 - f1_metrics: 0.7117 - val_loss: 0.6988 - val_categorical_accuracy: 0.7123 - val_precision: 0.6533 - val_recall: 0.7897 - val_f1_metrics: 0.7157\n",
            "Epoch 11/20\n",
            "3052/3052 - 11s - loss: 0.6192 - categorical_accuracy: 0.7507 - precision: 0.6137 - recall: 0.8640 - f1_metrics: 0.7184 - val_loss: 0.6967 - val_categorical_accuracy: 0.7136 - val_precision: 0.6487 - val_recall: 0.7953 - val_f1_metrics: 0.7151\n",
            "Epoch 12/20\n",
            "3052/3052 - 11s - loss: 0.6201 - categorical_accuracy: 0.7501 - precision: 0.6165 - recall: 0.8634 - f1_metrics: 0.7200 - val_loss: 0.6940 - val_categorical_accuracy: 0.7132 - val_precision: 0.6541 - val_recall: 0.7926 - val_f1_metrics: 0.7173\n",
            "Epoch 13/20\n",
            "3052/3052 - 11s - loss: 0.6193 - categorical_accuracy: 0.7502 - precision: 0.6205 - recall: 0.8627 - f1_metrics: 0.7225 - val_loss: 0.6935 - val_categorical_accuracy: 0.7123 - val_precision: 0.6526 - val_recall: 0.7992 - val_f1_metrics: 0.7191\n",
            "Epoch 14/20\n",
            "3052/3052 - 11s - loss: 0.6178 - categorical_accuracy: 0.7504 - precision: 0.6276 - recall: 0.8598 - f1_metrics: 0.7264 - val_loss: 0.6952 - val_categorical_accuracy: 0.7111 - val_precision: 0.6637 - val_recall: 0.7868 - val_f1_metrics: 0.7207\n",
            "Epoch 15/20\n",
            "3052/3052 - 11s - loss: 0.6196 - categorical_accuracy: 0.7502 - precision: 0.6359 - recall: 0.8533 - f1_metrics: 0.7295 - val_loss: 0.6945 - val_categorical_accuracy: 0.7099 - val_precision: 0.6559 - val_recall: 0.7944 - val_f1_metrics: 0.7190\n",
            "Epoch 16/20\n",
            "3052/3052 - 11s - loss: 0.6187 - categorical_accuracy: 0.7500 - precision: 0.6374 - recall: 0.8596 - f1_metrics: 0.7329 - val_loss: 0.6961 - val_categorical_accuracy: 0.7123 - val_precision: 0.6642 - val_recall: 0.7874 - val_f1_metrics: 0.7212\n",
            "Epoch 17/20\n",
            "3052/3052 - 11s - loss: 0.6180 - categorical_accuracy: 0.7506 - precision: 0.6422 - recall: 0.8584 - f1_metrics: 0.7354 - val_loss: 0.6942 - val_categorical_accuracy: 0.7111 - val_precision: 0.6548 - val_recall: 0.8019 - val_f1_metrics: 0.7215\n",
            "Epoch 18/20\n",
            "3052/3052 - 11s - loss: 0.6187 - categorical_accuracy: 0.7499 - precision: 0.6388 - recall: 0.8607 - f1_metrics: 0.7341 - val_loss: 0.6919 - val_categorical_accuracy: 0.7128 - val_precision: 0.6502 - val_recall: 0.8060 - val_f1_metrics: 0.7202\n",
            "Epoch 19/20\n",
            "3052/3052 - 11s - loss: 0.6209 - categorical_accuracy: 0.7476 - precision: 0.6403 - recall: 0.8586 - f1_metrics: 0.7343 - val_loss: 0.6921 - val_categorical_accuracy: 0.7119 - val_precision: 0.6570 - val_recall: 0.7963 - val_f1_metrics: 0.7204\n",
            "Epoch 20/20\n",
            "3052/3052 - 11s - loss: 0.6179 - categorical_accuracy: 0.7511 - precision: 0.6457 - recall: 0.8593 - f1_metrics: 0.7380 - val_loss: 0.6976 - val_categorical_accuracy: 0.7115 - val_precision: 0.6595 - val_recall: 0.7936 - val_f1_metrics: 0.7211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su6UMddaM01o",
        "outputId": "74f1140f-555a-42c4-e450-01d686478aa8"
      },
      "source": [
        "indiv = []\r\n",
        "for model in members:\r\n",
        "  indiv.append(f1_metrics(y_dev_cat, model.predict(x_test)))\r\n",
        "\r\n",
        "max(indiv)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.6822533>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWJYjYGol_Cs",
        "outputId": "61c74507-7853-4671-add3-b1cdfacdfd50"
      },
      "source": [
        "stack_model.evaluate(np.array(list(zip(*np.squeeze(test_predictions)))),y_dev_cat)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "357/357 [==============================] - 1s 3ms/step - loss: 0.7353 - categorical_accuracy: 0.6884 - precision: 0.6374 - recall: 0.7746 - f1_metrics: 0.7001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7353222966194153,\n",
              " 0.6884083151817322,\n",
              " 0.6373721361160278,\n",
              " 0.7746454477310181,\n",
              " 0.7001225352287292]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    }
  ]
}